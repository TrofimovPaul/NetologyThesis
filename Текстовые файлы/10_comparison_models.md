# Сравнение моделей

## Сравнение нейросетевых моделей

По всем метрикам лидирующую позицию занимает ruBERT base. Модель ruBERT tiny2 является достаточно неплохой, если учесть
тот факт, что она по всем метрикам стартует с заметно более низкой базы, но в ходе обучения постепенно приближается к
показателям остальных архитектур. Показатели моделей XLM-RoBERTa и DistilBERT достаточно близки, что свидетельствует в
пользу эффективности DistilBERT, у которого количество параметров меньше почти в 6 раз.


### ruBERT base
```
Accuracy: 0.75801
Hamming distance: 0.76153
                      precision    recall  f1-score
           micro avg       0.80      0.77      0.78
```

### XLM-RoBERTa
```
Accuracy: 0.74312
Hamming distance: 0.74774
                      precision    recall  f1-score
           micro avg       0.78      0.75      0.77
```

### DistilBERT
```
Accuracy: 0.70976
Hamming distance: 0.71629
                      precision    recall  f1-score
           micro avg       0.75      0.72      0.74
```
### ruBERT tiny2
```
Accuracy: 0.68557
Hamming distance: 0.69075
                      precision    recall  f1-score
           micro avg       0.76      0.70      0.73
```

Стоит подсветить, что минимизация функции потерь достигается раньше, чем максимизация метрик F1, Hamming distance,
Recall, что хорошо видно по графикам. Хотя минимальная функция потерь соответствует максимальному Accuracy, эта метрика
не несёт большого смысла в рамках поставленной задачи многоклассовой классификации. Более нужными выглядят F1 и Hamming
distance, максимизация которых происходит за счет быстрого роста Recall на фоне постепенного и периодического понижения
Precision – это также общее поведение для всех моделей. Также на графиках хорошо видится схожесть кривых метрик F1 и
Hamming distance, что говорит о близости смысла метрик.

## Сравнение классических и нейросетевых моделей

Сравнение классических и нейросетевых моделей в сводной таблице основных характеристик и метрик.

![](.\\Изображения\\comparison.png)

При сравнении моделей стоит опираться и на вес и на время обучения. Классические методы (TFIDF и логистическая
регрессия, деревья решений) являются самым быстрым решением, которое занимает относительно немного места – всего 110 МБ
для модели на униграммах. Но такой подход не даст высоких значений метрик. Хорошим вариантом для улучшения результатов
является ансамблирование моделей.

При тонкой настройке нейросетевые модели способны показывать высокое качество. Здесь следует не забывать о том, что
количество параметров, а соответственно вес модели и время на обучение, растут быстрее значений метрик. Поэтому для
успешного использования нейросетевых моделей необходимо обладать достаточными 
ресурсами, либо мириться с ограничениями и увеличением времени работы. Хорошим вариантом для улучшения качества
нейросетевых моделей может стать аугментация данных.
